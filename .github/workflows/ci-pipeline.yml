name: CI Pipeline

on:
  workflow_dispatch:
    inputs:
      run_bin_e2e:
        description: "Run Part 3: E2E Bin Datasets"
        default: "false"
        required: false
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
    types: [opened, synchronize, reopened]

jobs:
  # Part 1: Build & Deploy (Docker ‚Üí Artifact Registry ‚Üí Cloud Run)
  build-deploy:
    name: "1Ô∏è‚É£ Build & Deploy (Docker ‚Üí Artifacts)"
    runs-on: ubuntu-latest
    # Skip deployment for PR events to prevent race conditions with merge
    if: github.event_name != 'pull_request'
    permissions:
      contents: read
      id-token: write   # WIF required

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Auth (WIF)
        id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
          service_account:         ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2

      - name: "Resolve parameters & configure Docker"
        id: params
        env:
          REGION:     ${{ secrets.GCP_REGION }}
          PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          SERVICE:    ${{ secrets.GCP_SERVICE }}
          REPO_SEC:   ${{ secrets.GCP_AR_REPO }}   # may be empty
        run: |
          set -euo pipefail
          REPO="${REPO_SEC:-run}"   # default to 'run' if secret is empty
          echo "REGION=${REGION}"       | tee -a "$GITHUB_OUTPUT"
          echo "PROJECT_ID=${PROJECT_ID}" | tee -a "$GITHUB_OUTPUT"
          echo "SERVICE=${SERVICE}"     | tee -a "$GITHUB_OUTPUT"
          echo "REPO=${REPO}"           | tee -a "$GITHUB_OUTPUT"
          gcloud auth configure-docker "${REGION}-docker.pkg.dev" --quiet

      - name: "Build & Push image (Docker ‚Üí Artifact Registry)"
        env:
          REGION:     ${{ steps.params.outputs.REGION }}
          PROJECT_ID: ${{ steps.params.outputs.PROJECT_ID }}
          SERVICE:    ${{ steps.params.outputs.SERVICE }}
          REPO:       ${{ steps.params.outputs.REPO }}
          SHA:        ${{ github.sha }}
        run: |
          set -euo pipefail
          DOMAIN="${REGION}-docker.pkg.dev"
          IMAGE="${DOMAIN}/${PROJECT_ID}/${REPO}/${SERVICE}:${SHA}"
          echo "Building IMAGE=${IMAGE}"
          docker build -t "${IMAGE}" .
          docker push "${IMAGE}"
          echo "image=${IMAGE}" >> "$GITHUB_OUTPUT"

      - name: "Deploy to Cloud Run (latest)"
        env:
          REGION:     ${{ steps.params.outputs.REGION }}
          PROJECT_ID: ${{ steps.params.outputs.PROJECT_ID }}
          SERVICE:    ${{ steps.params.outputs.SERVICE }}
          REPO:       ${{ steps.params.outputs.REPO }}
          SHA:        ${{ github.sha }}
        run: |
          set -euo pipefail
          DOMAIN="${REGION}-docker.pkg.dev"
          IMAGE="${DOMAIN}/${PROJECT_ID}/${REPO}/${SERVICE}:${SHA}"
          echo "Deploying IMAGE=${IMAGE}"
          gcloud run deploy "${SERVICE}" \
            --project "${PROJECT_ID}" \
            --region "${REGION}" \
            --image  "${IMAGE}" \
            --platform managed \
            --allow-unauthenticated \
            --memory=3Gi --cpu=2 \
            --min-instances=0 --max-instances=3 \
            --timeout=600 --quiet

      - name: "Redirect Traffic to Latest Revision"
        env:
          REGION:     ${{ steps.params.outputs.REGION }}
          PROJECT_ID: ${{ steps.params.outputs.PROJECT_ID }}
          SERVICE:    ${{ steps.params.outputs.SERVICE }}
        run: |
          set -euo pipefail
          echo "Redirecting 100% traffic to latest revision..."
          
          # Get the latest revision name
          LATEST_REVISION=$(gcloud run revisions list \
            --service="${SERVICE}" \
            --project="${PROJECT_ID}" \
            --region="${REGION}" \
            --sort-by="~metadata.creationTimestamp" \
            --limit=1 \
            --format="value(metadata.name)")
          
          echo "Latest revision: ${LATEST_REVISION}"
          
          # Redirect 100% traffic to latest revision
          gcloud run services update-traffic "${SERVICE}" \
            --project="${PROJECT_ID}" \
            --region="${REGION}" \
            --to-revisions="${LATEST_REVISION}=100" \
            --quiet
          
          echo "‚úÖ Traffic redirected to ${LATEST_REVISION}"

  # Part 2: E2E Validation (Validate deployment with e2e.py)
  e2e-validation:
    name: "2Ô∏è‚É£ E2E (Density/Flow)"
    runs-on: ubuntu-latest
    needs: build-deploy
    # Skip E2E validation for PR events (only needed for main branch)
    if: github.event_name != 'pull_request'
    permissions:
      contents: read
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run E2E Tests
      run: |
        echo "=== Running E2E Tests for Deployment Validation ==="
        echo "Testing Cloud Run deployment with e2e.py"
        python e2e.py --cloud

  # Part 3: E2E Bin Dataset Generation and Validation
  # NOTE: Disabled by default during Front-End Simplification Epic (#261)
  # To enable: workflow_dispatch with run_bin_e2e=true
  bin-dataset-validation:
    name: "3Ô∏è‚É£ E2E (Bin Datasets)"
    runs-on: ubuntu-latest
    needs: e2e-validation
    # Skip bin validation for PR events (only needed for main branch)
    if: github.event_name != 'pull_request'
    permissions:
      contents: read
      id-token: write   # WIF required for GCS access
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Auth (WIF)
      id: auth
      uses: google-github-actions/auth@v2
      with:
        workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
        service_account:         ${{ secrets.GCP_SERVICE_ACCOUNT }}
    
    - name: Setup gcloud
      uses: google-github-actions/setup-gcloud@v2
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Early exit if feature flag is off
      env:
        RUN_BIN_E2E: ${{ github.event.inputs.run_bin_e2e || 'false' }}
      run: |
        if [ "$RUN_BIN_E2E" != "true" ]; then
          echo "üîï Skipping bin dataset validation (RUN_BIN_E2E=${RUN_BIN_E2E})."
          echo "This job completes as a NO-OP to keep downstream 'needs' unblocked."
          exit 0
        fi
    
    - name: Enable Bin Dataset Environment
      run: |
        echo "=== Configuring Bin Dataset Validation Environment ==="
        echo "ENABLE_BIN_DATASET=true" >> $GITHUB_ENV
        echo "BIN_MAX_FEATURES=10000" >> $GITHUB_ENV
        echo "DEFAULT_BIN_TIME_WINDOW_SECONDS=60" >> $GITHUB_ENV
        echo "DEFAULT_BIN_SIZE_KM=0.1" >> $GITHUB_ENV
        echo "MAX_BIN_GENERATION_TIME_SECONDS=120" >> $GITHUB_ENV
    
    - name: Generate Bin Datasets
      run: |
        echo "=== Generating Bin Datasets on Cloud Run ==="
        echo "Environment: ENABLE_BIN_DATASET=true"
        echo "Calling /api/density-report with bin generation enabled..."
        
        # Generate bin datasets via density report API
        RESPONSE=$(curl -X POST "https://run-density-ln4r3sfkha-uc.a.run.app/api/density-report" \
          -H "Content-Type: application/json" \
          -d '{
            "paceCsv": "data/runners.csv",
            "densityCsv": "data/segments.csv", 
            "startTimes": {"Full": 420, "10K": 440, "Half": 460},
            "enable_bin_dataset": true
          }' \
          --max-time 300 \
          --write-out "HTTPSTATUS:%{http_code}" \
          --silent)
        
        HTTP_CODE=$(echo "$RESPONSE" | grep -o "HTTPSTATUS:[0-9]*" | cut -d: -f2)
        RESPONSE_BODY=$(echo "$RESPONSE" | sed 's/HTTPSTATUS:[0-9]*$//')
        
        if [ "$HTTP_CODE" = "200" ]; then
          echo "‚úÖ Bin Dataset Generation: COMPLETED"
          echo "üì¶ Bin datasets generated and uploaded to GCS"
          echo "Response size: $(echo "$RESPONSE_BODY" | wc -c) characters"
        else
          echo "‚ùå Bin Dataset Generation Failed: HTTP $HTTP_CODE"
          echo "Response: $RESPONSE_BODY"
          exit 1
        fi
    
    - name: Verify Bin Artifacts Generated
      run: |
        echo "=== Verifying Bin Artifacts in GCS ==="
        REPORT_DATE=$(date +%Y-%m-%d)
        echo "Checking for bin artifacts in gs://run-density-reports/$REPORT_DATE/"
        
        # Check for bin artifacts
        if gsutil ls gs://run-density-reports/$REPORT_DATE/bins.geojson.gz; then
          echo "‚úÖ Found bins.geojson.gz"
          GEOJSON_SIZE=$(gsutil ls -l gs://run-density-reports/$REPORT_DATE/bins.geojson.gz | awk '{print $1}')
          echo "‚úÖ Size: $GEOJSON_SIZE bytes"
        else
          echo "‚ùå Missing bins.geojson.gz"
          exit 1
        fi
        
        if gsutil ls gs://run-density-reports/$REPORT_DATE/bins.parquet; then
          echo "‚úÖ Found bins.parquet"
          PARQUET_SIZE=$(gsutil ls -l gs://run-density-reports/$REPORT_DATE/bins.parquet | awk '{print $1}')
          echo "‚úÖ Size: $PARQUET_SIZE bytes"
        else
          echo "‚ùå Missing bins.parquet"
          exit 1
        fi
    
    - name: Validate Bin Dataset Quality
      run: |
        echo "=== Bin Dataset Quality Validation ==="
        REPORT_DATE=$(date +%Y-%m-%d)
        
        # Download artifacts for validation (need both geojson.gz and parquet)
        mkdir -p ./validation_temp/$REPORT_DATE
        gsutil cp gs://run-density-reports/$REPORT_DATE/bins.geojson.gz ./validation_temp/$REPORT_DATE/
        gsutil cp gs://run-density-reports/$REPORT_DATE/bins.parquet ./validation_temp/$REPORT_DATE/
        gsutil cp gs://run-density-reports/$REPORT_DATE/map_data_*.json ./validation_temp/$REPORT_DATE/ || echo "Map data will be checked separately"
        
        # Run validation using existing tools
        python scripts/validation/verify_bins.py --reports-dir ./validation_temp
        
        echo "‚úÖ Bin dataset quality validation completed"

  # Part 4: Automated Release (GitHub release creation)
  automated-release:
    name: "4Ô∏è‚É£ Automated Release"
    runs-on: ubuntu-latest
    needs: [build-deploy, e2e-validation, bin-dataset-validation]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    permissions:
      contents: write
      id-token: write
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Check version and determine release action
      id: version-check
      run: |
        echo "=== Version and Release Strategy Check ==="
        
        # Get versions using Python
        CODE_VERSION=$(python -c "from app.version import get_current_version; print(get_current_version())")
        GIT_TAG=$(python -c "from app.version import get_latest_git_tag; print(get_latest_git_tag())")
        
        echo "Current version in code: $CODE_VERSION"
        echo "Latest git tag: $GIT_TAG"
        
        # Determine action based on version comparison
        if [ "$CODE_VERSION" = "$GIT_TAG" ]; then
            echo "‚úÖ Code version matches latest tag"
            echo "üîç Checking if release exists for this version..."
            echo "action=check_existing" >> $GITHUB_OUTPUT
            echo "version=$CODE_VERSION" >> $GITHUB_OUTPUT
        else
            echo "üöÄ Code version is newer than latest tag - new feature completed!"
            echo "üì¶ Will create new release for version: $CODE_VERSION"
            echo "action=create_new" >> $GITHUB_OUTPUT
            echo "version=$CODE_VERSION" >> $GITHUB_OUTPUT
            echo "previous_tag=$GIT_TAG" >> $GITHUB_OUTPUT
        fi
    
    - name: Verify version strategy
      run: |
        echo "=== Version Strategy Verification ==="
        python -c "
        from app.version import get_current_version, get_latest_git_tag
        import sys
        
        code_version = get_current_version()
        git_tag = get_latest_git_tag()
        
        print('Final verification:')
        print('Current version in code:', code_version)
        print('Latest git tag:', git_tag)
        
        if code_version == git_tag:
            print('‚úÖ Standard release: Code version matches git tag')
        elif code_version > git_tag:
            print('üöÄ New feature release: Code version is newer than git tag')
        else:
            print('‚ùå ERROR: Code version is older than git tag - this should not happen')
            sys.exit(1)
        
        print('‚úÖ Version strategy validation passed!')
        "
    
    - name: Get final version for release
      id: version
      run: |
        python -c "
        from app.version import get_current_version
        version = get_current_version()
        print(f'version={version}')
        " >> $GITHUB_OUTPUT
    
    - name: Check if release already exists (for existing versions)
      id: check-release
      if: steps.version-check.outputs.action == 'check_existing'
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        echo "Checking if release ${{ steps.version.outputs.version }} already exists..."
        if gh release view ${{ steps.version.outputs.version }} >/dev/null 2>&1; then
          echo "exists=true" >> $GITHUB_OUTPUT
          echo "‚úÖ Release ${{ steps.version.outputs.version }} already exists - will skip creation"
        else
          echo "exists=false" >> $GITHUB_OUTPUT
          echo "‚úÖ Release ${{ steps.version.outputs.version }} does not exist - will create"
        fi
    
    - name: Skip Release Creation (Already Exists)
      if: steps.version-check.outputs.action == 'check_existing' && steps.check-release.outputs.exists == 'true'
      run: |
        echo "=== Release Already Exists ==="
        echo "‚úÖ Release ${{ steps.version.outputs.version }} already exists"
        echo "Skipping release creation to avoid duplicates"
        echo "This is expected behavior when multiple pushes occur with the same version"
    
    - name: Create GitHub Release (New Version)
      if: steps.version-check.outputs.action == 'create_new' || (steps.version-check.outputs.action == 'check_existing' && steps.check-release.outputs.exists == 'false')
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        echo "=== Creating GitHub Release ==="
        
        if [ "${{ steps.version-check.outputs.action }}" = "create_new" ]; then
          echo "üöÄ Creating NEW release for version: ${{ steps.version.outputs.version }}"
          echo "üìà Previous version was: ${{ steps.version-check.outputs.previous_tag }}"
          RELEASE_TYPE="New Feature Release"
        else
          echo "üîÑ Creating release for existing version: ${{ steps.version.outputs.version }}"
          RELEASE_TYPE="Standard Release"
        fi
        
        # Double-check release doesn't exist before creating
        if gh release view ${{ steps.version.outputs.version }} >/dev/null 2>&1; then
          echo "‚ùå ERROR: Release ${{ steps.version.outputs.version }} already exists! This should not happen."
          echo "Skipping release creation to avoid duplicate."
          exit 0
        fi
        
        gh release create ${{ steps.version.outputs.version }} \
          --title "$RELEASE_TYPE ${{ steps.version.outputs.version }}" \
          --notes "## üöÄ $RELEASE_TYPE ${{ steps.version.outputs.version }}

        This release was created automatically from the CI pipeline.

        ### Release Type
        - **Type**: $RELEASE_TYPE
        - **Previous Version**: ${{ steps.version-check.outputs.previous_tag || 'Same version' }}
        - **New Features**: ${{ steps.version-check.outputs.action == 'create_new' && 'Yes - version bumped for new functionality' || 'Standard release' }}

        ### Validation
        - ‚úÖ Build & Deploy completed successfully
        - ‚úÖ E2E validation passed (density/flow)
        - ‚úÖ Bin dataset validation passed
        - ‚úÖ Quality gate enforced before release

        ### Workflow
        Deploy ‚Üí E2E Test ‚Üí Bin Validation ‚Üí Release (only if all tests pass)

        ### Next Steps
        1. Review the release notes and attached assets
        2. Verify production deployment is working
        3. Monitor Cloud Run performance"
    
    - name: Upload Release Assets
      if: steps.version-check.outputs.action == 'create_new' || (steps.version-check.outputs.action == 'check_existing' && steps.check-release.outputs.exists == 'false')
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        echo "=== Uploading Release Assets ==="
        # Find the latest reports
        if [ -d "reports" ]; then
          LATEST_DATE=$(ls -1 reports/ | sort | tail -1)
          if [ -n "$LATEST_DATE" ] && [ -d "reports/$LATEST_DATE" ]; then
            echo "Uploading reports from reports/$LATEST_DATE"
            gh release upload ${{ steps.version.outputs.version }} reports/$LATEST_DATE/*.md reports/$LATEST_DATE/*.csv
          fi
        fi
        
        # Upload E2E test results if available
        if [ -d "e2e_tests" ]; then
          LATEST_E2E_DATE=$(ls -1 e2e_tests/ | sort | tail -1)
          if [ -n "$LATEST_E2E_DATE" ] && [ -d "e2e_tests/$LATEST_E2E_DATE" ]; then
            echo "Uploading E2E results from e2e_tests/$LATEST_E2E_DATE"
            gh release upload ${{ steps.version.outputs.version }} e2e_tests/$LATEST_E2E_DATE/*.md
          fi
        fi

